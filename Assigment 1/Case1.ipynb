{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZEzN0FhAXcY"
   },
   "source": [
    "# **The Problem & Business Importance**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHWy8k7SAZLx"
   },
   "source": [
    "# **Data Identification & Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "plINWFh7Bgh5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "#test\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split , KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6Jvdrwm5OTq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('i4talent_dataset.csv')\n",
    "df['datum'] = pd.to_datetime(df['datum'])\n",
    "df['geboortedatum'] = pd.to_datetime(df['geboortedatum'])\n",
    "df['indiensttreding_datum'] = pd.to_datetime(df['indiensttreding_datum'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JXnHTqgh5WGp",
    "outputId": "72520840-948d-446f-d6d6-1017168ac6be"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "VKwqRLC-5_IZ",
    "outputId": "89956ba4-116f-4b0f-eb74-70161c7bc364"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbDDKRwf7Y_d",
    "outputId": "42a86b64-0b52-4eec-b3f0-4f420d1080e4"
   },
   "outputs": [],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYCYA9i28u_8",
    "outputId": "1ae83b06-6d65-4c62-fce0-d367713f3377"
   },
   "outputs": [],
   "source": [
    "columns_categorical_with_nas = ['stad', 'afdeling']\n",
    "for b in columns_categorical_with_nas:\n",
    "    unique_values = df[b].value_counts()\n",
    "    print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7omAH42L8a2D",
    "outputId": "87eb756c-c506-4ccb-b41f-676e241a2f3d"
   },
   "outputs": [],
   "source": [
    "df['leeftijd'] = df['leeftijd'].fillna((df['datum'] - df['geboortedatum']).dt.days // 365)\n",
    "df['lengte_dienst'] = df['lengte_dienst'].fillna((df['datum'] - df['indiensttreding_datum']).dt.days // 365)\n",
    "df['stad'] = df['stad'].fillna(df['stad'].mode())\n",
    "df['afdeling'] = df['afdeling'].fillna(df['afdeling'].mode())\n",
    "\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "4pN76r4P8ip_",
    "outputId": "59b58995-917d-476e-f78a-961e868e8886"
   },
   "outputs": [],
   "source": [
    "columns_numerical_with_nas = ['leeftijd', 'lengte_dienst']\n",
    "for col in columns_numerical_with_nas:\n",
    "    plt.hist(df[col], bins=100)\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iCGSj9AbGNIL",
    "outputId": "1a61ed89-4487-46e3-aa41-1d2894b3fb06"
   },
   "outputs": [],
   "source": [
    "columns_to_delete = ['geboortedatum', 'WerknemerID', 'uitdiensttreding_datum', 'indiensttreding_datum', 'geslacht', 'uitdiensttreding_type', 'datum', 'STATUS_JAAR', 'uitdiensttreding_reden']\n",
    "df_new = df.drop(columns=columns_to_delete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "W4hkCTGFI89z",
    "outputId": "72b1fb39-7491-4a86-cd5f-a7c0970160d2"
   },
   "outputs": [],
   "source": [
    "df_with_dummies = pd.get_dummies(df_new, columns=['stad', 'afdeling', 'geslacht_id', 'STATUS', 'BUSINESS_UNIT'], drop_first=True)\n",
    "df_with_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2OVALsLKODq"
   },
   "source": [
    "geboortedatum, WerknemerID, uitdiensttreding_datum, indiensttreding_datum, geslacht, uitdiensttreding_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBA427i_KbZD"
   },
   "source": [
    "Dummies: 'stad', 'afdeling', 'geslachtID', 'uitdiensttreding_reden', 'Status', 'BUSINESS_UNIT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQD_lZVrJQTy",
    "outputId": "50803d7c-355c-4669-aef5-9ab5e9e8e5cc"
   },
   "outputs": [],
   "source": [
    "df_with_dummies['leeftijd'] = df_with_dummies['leeftijd'].astype(int)\n",
    "df_with_dummies['lengte_dienst'] = df_with_dummies['lengte_dienst'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nGpDbGgP2eK"
   },
   "outputs": [],
   "source": [
    "#Used later for model evaluation\n",
    "model_scores = {}\n",
    "\n",
    "#You can download the pretrained models here : https://github.com/dvanaanhout/GROUP5\n",
    "#Saves time running the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_with_dummies.drop(columns=['STATUS_Beëindigd'])\n",
    "y = df_with_dummies['STATUS_Beëindigd']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLPPLuhchdar",
    "outputId": "f820ae07-b842-4abe-ca6f-808e939c7431"
   },
   "outputs": [],
   "source": [
    "\n",
    "saved_model_name = 'model_lr.joblib'\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_lr = loaded_model\n",
    "else:\n",
    "    model_lr = LogisticRegression()\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    joblib.dump(model_lr, saved_model_name)\n",
    "\n",
    "y_pred = model_lr.predict(X_test)\n",
    "\n",
    "train_score = model_lr.score(X_train, y_train)\n",
    "test_score = model_lr.score(X_test, y_test)\n",
    "\n",
    "\n",
    "model_scores['Logistic Regression'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score\n",
    "}\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = model_lr.coef_[0]\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': coefficients,\n",
    "    'Importance': np.abs(coefficients)\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Logistic Regression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_name = 'model_lr_TUNED.joblib'\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_lr_TUNED = loaded_model\n",
    "else:\n",
    "    grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_lr_TUNED = grid_search.best_estimator_\n",
    "    joblib.dump(model_lr_TUNED, saved_model_name)\n",
    "\n",
    "y_pred = model_lr_TUNED.predict(X_test)\n",
    "\n",
    "train_score = model_lr_TUNED.score(X_train, y_train)\n",
    "test_score = model_lr_TUNED.score(X_test, y_test)\n",
    "\n",
    "\n",
    "model_scores['Logistic Regression TUNED'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score\n",
    "}\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_name = 'model_HGBC.joblib'\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    best_model_HGBC = loaded_model\n",
    "\n",
    "else:\n",
    "    model_hgb = HistGradientBoostingClassifier()\n",
    "\n",
    "\n",
    "    model_hgb.fit(X_train, y_train)\n",
    "    best_model_HGBC = model_hgb\n",
    "    joblib.dump(best_model_HGBC, saved_model_name)\n",
    "\n",
    "\n",
    "y_pred = best_model_HGBC.predict(X_test)\n",
    "\n",
    "train_score = best_model_HGBC.score(X_train, y_train)\n",
    "test_score = best_model_HGBC.score(X_test, y_test)\n",
    "\n",
    "\n",
    "model_scores['Hist Gradient Boosting'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score,\n",
    "}\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(f\"Model Parameters: {best_model_HGBC.get_params()}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_name = 'model_HGBC_TUNED.joblib'\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_HGBC_TUNED = loaded_model\n",
    "else:\n",
    "    model_HGBC_TUNED = HistGradientBoostingClassifier()\n",
    "    param_grid = {\n",
    "        'max_iter': [100, 200,300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7, 9, 21, 25],\n",
    "        'min_samples_leaf': [1, 5, 10, 15, 20]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=model_HGBC_TUNED, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model_HGBC_TUNED = grid_search.best_estimator_\n",
    "    joblib.dump(best_model_HGBC_TUNED, saved_model_name)\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    model_HGBC_TUNED = best_model_HGBC_TUNED\n",
    "\n",
    "\n",
    "y_pred = model_HGBC_TUNED.predict(X_test)\n",
    "\n",
    "train_score = model_HGBC_TUNED.score(X_train, y_train)\n",
    "test_score = model_HGBC_TUNED.score(X_test, y_test)\n",
    "\n",
    "model_scores['Hist Gradient Boosting TUNED'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score,\n",
    "}\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "qQTZpvSCTVqG",
    "outputId": "15518315-b3e2-4eb4-d7ec-0ae85b2beddc"
   },
   "outputs": [],
   "source": [
    "saved_model_name = 'model_KNN.joblib'\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_knn = loaded_model\n",
    "else:\n",
    "    model_knn = KNeighborsClassifier()\n",
    "    model_knn.fit(X_train, y_train)\n",
    "    joblib.dump(model_knn, saved_model_name)\n",
    "\n",
    "y_pred = model_knn.predict(X_test)\n",
    "\n",
    "train_score = model_knn.score(X_train, y_train)\n",
    "test_score = model_knn.score(X_test, y_test)\n",
    "\n",
    "model_scores['KNN'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score,\n",
    "}\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saved_model_name = 'model_KNN_TUNED.joblib'\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11]\n",
    "}\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_knn_TUNED = loaded_model\n",
    "else:\n",
    "    grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_knn_TUNED = grid_search.best_estimator_\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    joblib.dump(model_knn_TUNED, saved_model_name)\n",
    "\n",
    "y_pred = model_knn_TUNED.predict(X_test)\n",
    "\n",
    "train_score = model_knn_TUNED.score(X_train, y_train)\n",
    "test_score = model_knn_TUNED.score(X_test, y_test)\n",
    "\n",
    "\n",
    "model_scores['KNN TUNED'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score,\n",
    "}\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_name = 'model_XGBoost.joblib'\n",
    "\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_xgboost = loaded_model\n",
    "else:\n",
    "    model_xgboost = XGBClassifier()\n",
    "    model_xgboost.fit(X_train, y_train)\n",
    "    print(f\"Model Parameters: {model_xgboost.get_params()}\")\n",
    "    joblib.dump(model_xgboost, saved_model_name)\n",
    "\n",
    "y_pred = model_xgboost.predict(X_test)\n",
    "\n",
    "train_score = model_xgboost.score(X_train, y_train)\n",
    "test_score = model_xgboost.score(X_test, y_test)\n",
    "\n",
    "\n",
    "model_scores['XGBoost Classifier'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score,\n",
    "}\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_name = 'model_XGBoost_TUNED.joblib'\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_xgboost_TUNED = loaded_model\n",
    "else:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    }\n",
    "    grid_search = GridSearchCV(XGBClassifier(), param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_xgboost_TUNED = grid_search.best_estimator_\n",
    "    print(f\"Model Parameters: {model_xgboost_TUNED.get_params()}\")\n",
    "    joblib.dump(model_xgboost_TUNED, saved_model_name)\n",
    "\n",
    "y_pred = model_xgboost_TUNED.predict(X_test)\n",
    "\n",
    "train_score = model_xgboost_TUNED.score(X_train, y_train)\n",
    "test_score = model_xgboost_TUNED.score(X_test, y_test)\n",
    "\n",
    "\n",
    "model_scores['XGBoost Classifier TUNED'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score,\n",
    "}\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TeiW2Ei4leBm",
    "outputId": "2fd30065-1ae0-4934-cef5-f81aad4454d2"
   },
   "outputs": [],
   "source": [
    "saved_model_name = 'model_RandomForest.joblib'\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_RF = loaded_model\n",
    "else:\n",
    "    model_RF = RandomForestClassifier(random_state=42)\n",
    "    model_RF.fit(X_train, y_train)\n",
    "    joblib.dump(model_RF, saved_model_name)\n",
    "\n",
    "y_pred = model_RF.predict(X_test)\n",
    "\n",
    "train_score = model_RF.score(X_train, y_train)\n",
    "test_score = model_RF.score(X_test, y_test)\n",
    "\n",
    "\n",
    "model_scores['Random Forest Classifier'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score\n",
    "}\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_RF.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_name = 'model_RandomForest_TUNED.joblib'\n",
    "\n",
    "if os.path.exists(saved_model_name):\n",
    "    loaded_model = joblib.load(saved_model_name)\n",
    "    model_RF_TUNED = loaded_model\n",
    "else:\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_RF_TUNED = grid_search.best_estimator_\n",
    "    joblib.dump(model_RF_TUNED, saved_model_name)\n",
    "\n",
    "y_pred = model_RF_TUNED.predict(X_test)\n",
    "\n",
    "train_score = model_RF_TUNED.score(X_train, y_train)\n",
    "test_score = model_RF_TUNED.score(X_test, y_test)\n",
    "\n",
    "model_scores['Random Forest Classifier TUNED'] = {\n",
    "    'Train Score': train_score,\n",
    "    'Test Score': test_score\n",
    "}\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_RF_TUNED.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "yM-ecdgCQlhv",
    "outputId": "ccc13dce-8b41-45f2-bad2-9aa88f738d8c"
   },
   "outputs": [],
   "source": [
    "models = list(model_scores.keys())\n",
    "train_scores = [model_scores[model][\"Train Score\"] for model in models]\n",
    "test_scores = [model_scores[model][\"Test Score\"] for model in models]\n",
    "\n",
    "x = range(len(models))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x, train_scores, width=0.4, label='Train Score', color='b', align='center')\n",
    "plt.bar([p + 0.4 for p in x], test_scores, width=0.4, label='Test Score', color='orange', align='center')\n",
    "\n",
    "print(x)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Train and Test Scores of Different Models')\n",
    "plt.xticks([p + 0.2 for p in x], models , rotation =90)\n",
    "plt.ylim(0.9, 1)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find at employees at risk of leaving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_with_dummies.drop('STATUS_Beëindigd', axis=1)\n",
    "y = df_with_dummies['STATUS_Beëindigd']\n",
    "print(X.shape)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "predicted_vals = []\n",
    "\n",
    "for i, j in kf.split(X):\n",
    "    X_train, X_test = X.iloc[i], X.iloc[j]\n",
    "    y_train, y_test = y.iloc[i], y.iloc[j]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    print(X_train.shape)\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_vals.extend(predictions)\n",
    "\n",
    "df_n_dummies = pd.get_dummies(df , columns=['STATUS'] , drop_first=True)\n",
    "df['pred_STATUS_Beëindigd'] = predicted_vals\n",
    "\n",
    "at_risk_employees = df_n_dummies[(df_n_dummies['pred_STATUS_Beëindigd'] == True) & (df_n_dummies['STATUS_Beëindigd'] == False)]\n",
    "at_risk_employees\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
